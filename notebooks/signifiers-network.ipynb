{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a4fe16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import DistilBertTokenizer\n",
    "from scipy.sparse import csr_matrix, lil_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b56278",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f2f06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dreams = pd.read_csv(\"../data/dreams/dreams_syuzhet_df.csv\")  # from https://github.com/SJD1882/IGR204-DataViz-Dream-Bank-Project/blob/master/notebooks/Dream_Bank_Data_Preprocessing.ipynb\n",
    "df_dreams.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be0c406",
   "metadata": {},
   "source": [
    "### Dataviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2e064c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "df_dreams[\"dreamer\"].value_counts().plot(kind=\"bar\")\n",
    "plt.xlabel(\"Dreamer\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Dreamer Count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8160580",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dreams[\"text_cleaned\"].apply(lambda x: len(str(x).split())).plot(kind=\"hist\", bins=50, figsize=(10,5))\n",
    "plt.xlabel(\"Number of Words in text_cleaned\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Distribution of Word Counts in text_cleaned\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d7d638d",
   "metadata": {},
   "source": [
    "## model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b27fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\", max_length=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcfb02cc",
   "metadata": {},
   "source": [
    "# Staged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f04e238",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_wordByDocMatrix(l_inputs, vocab_size, verbose=False):\n",
    "    matrix_wbd = lil_matrix(np.zeros((vocab_size, len(l_inputs)), dtype=int))\n",
    "    for i, input in enumerate(l_inputs):\n",
    "        for id_token in input:\n",
    "            matrix_wbd[id_token,i] = matrix_wbd[id_token,i]+1\n",
    "        if verbose and i % 1 == 0:\n",
    "            print(f\"Processed {i} texts\")\n",
    "    matrix_wbd = (matrix_wbd>=1).astype(int)\n",
    "    return matrix_wbd\n",
    "\n",
    "def create_wordByWordAdjacency(matrix_wbd, k=0):\n",
    "    matrix_wbw = (matrix_wbd @ matrix_wbd.T).astype(np.float32)\n",
    "    a = matrix_wbw.diagonal()\n",
    "    mask = a!=0\n",
    "    a[mask] = 1/(a[mask]+k)\n",
    "    adjacency = csr_matrix(np.diag(a))@matrix_wbw\n",
    "    sparsity = adjacency.count_nonzero()/np.multiply(*adjacency.shape)\n",
    "    print(f\"Created adjacency with sparsity: {sparsity}\")\n",
    "    return adjacency\n",
    "\n",
    "def preprocess_texts(l_texts, tokenizer, k=0):\n",
    "    l_inputs = [tokenizer(x, truncation=False, padding=False)[\"input_ids\"][1:-1] for x in l_texts]\n",
    "    matrix_wbd = create_wordByDocMatrix(l_inputs, tokenizer.vocab_size)\n",
    "    adjacency = create_wordByWordAdjacency(matrix_wbd, k=k)\n",
    "    return adjacency\n",
    "\n",
    "def convert_toEdgeIndex(adjacency):\n",
    "    dst = adjacency.indices\n",
    "    a = np.arange(len(adjacency.indices))\n",
    "    l = []\n",
    "    for i, x in enumerate(a):\n",
    "       l.append(np.nonzero(adjacency.indptr>x)[0][0]-1)\n",
    "       if i % 10000 == 0:\n",
    "           print(f\"Processed {i} edges over {len(a)}\")\n",
    "    src = np.array(l)\n",
    "    return src, dst\n",
    " \n",
    "\n",
    "# unit tests\n",
    "l_texts = [\n",
    "    \"chicken rice\",\n",
    "    \"chicken chicken\",\n",
    "    \"rice noodles\",\n",
    "    \"noodles soup\",\n",
    "    \"noodles rice\"\n",
    "]\n",
    "\n",
    "adjacency = preprocess_texts(l_texts, tokenizer, k=0)\n",
    "mask = adjacency.diagonal()!=0\n",
    "print(np.nonzero(mask))\n",
    "print(tokenizer.decode(np.nonzero(mask)[0].tolist()))\n",
    "adjacency = adjacency[mask,:][:,mask]\n",
    "print(adjacency.toarray())\n",
    "\n",
    "M = np.zeros_like(adjacency.toarray())\n",
    "src, dst = convert_toEdgeIndex(adjacency)\n",
    "for s, d in zip(src, dst):\n",
    "    M[s,d] = adjacency[s,d]\n",
    "assert (M==adjacency.toarray()).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487fa7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dreams = df_dreams.loc[df_dreams[\"dreamer\"] == \"dorothea\"].reset_index(drop=True)\n",
    "l_texts = df_dreams[\"text_cleaned\"].tolist()\n",
    "adjacency = preprocess_texts(l_texts, tokenizer, k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88cdf8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = adjacency[(adjacency!=0)].A1\n",
    "a = a[a!=1]\n",
    "# plot the off diagonal value of adjacency\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.hist(a, bins=50, color='skyblue', edgecolor='black')\n",
    "plt.xlabel(\"Value\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Distribution of Off-Diagonal Values in Adjacency Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab3ad7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "src, dst = convert_toEdgeIndex(adjacency)\n",
    "order = np.argsort(adjacency.data)[::-1]\n",
    "src, dst, data = src[order], dst[order], adjacency.data[order]\n",
    "mask = src != dst\n",
    "src, dst, data = src[mask], dst[mask], data[mask]\n",
    "src, dst, data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8a014c",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 1000\n",
    "for s, d, v in zip(src, dst, data):\n",
    "    if count == 0:\n",
    "        break\n",
    "    s = tokenizer.decode([s])\n",
    "    d = tokenizer.decode([d])\n",
    "    if (d not in [\"go\", \"ask\", \"say\", \"one\", \"find\", \"get\", \"see\", \"come\", \"back\", \"take\", \"know\", \"think\", \"want\", \"tell\", \"look\", \"make\", \"like\", \"time\", \"day\", \"way\", \"thing\",\n",
    "                 \"room\", \"house\", \"bed\", \"sleep\", \"night\", \"door\", \"walk\", \"people\"]\n",
    "        ) and (\"#\" not in d) and (\"#\" not in s) and (len(d)>2):\n",
    "        print(s, \"-\", d, \":\", v)\n",
    "        count -= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18fd909",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = ((df_dreams[\"text_cleaned\"].apply(lambda u: \"mountain\" in u.lower()\n",
    "                                         and \"mother\" in u.lower() \n",
    "                                         )))\n",
    "for x in df_dreams.loc[mask, \"content\"].values:\n",
    "    print(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bertaphore",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
